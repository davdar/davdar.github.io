<!doctype html>
<html lang="en">
<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <!-- Darais CSS -->
  <link rel="stylesheet" href="http://david.darais.com/css/darais-v0.0.0.1.css">

  <!-- Title -->
  <meta name="title" content="Lecture Notes: 19">

</head>

<body>

<main>

<pre class=markdown>

# Program Analysis via Abstract Interpretation

## Context

Until now we've seen two different kinds of interpreters:

- *standard interpreters* which map expressions to values
- *type checkers* which map expressions to the type of values they evaluate to

A standard interpreter defines the *meaning* of a program in a programming
language. A type checker (when it succeeds) amounts to *evidence* that a
program will (1) not crash due to a runtime type (or scope) error, and (2) if
it does return a value, what type of value will it return. The “spec” for the
type checker is called a *type system*, and was written with funny inference
rules. However, the implementation of a type checker looked a lot like a
standard interpreter—in fact type checkers *are* a kind of interpreter.

Whereas a standard interpreter returns a single value, and a type checker
returns a type which classifies a large set of possible values (e.g., bool vs
int), a program analyzer typically gives you something in-between: a
fine-grained set of possible values.
 
A common abstraction to use for arithmetic programs is called the “interval
abstract domain”. These are the results of a program analysis, and are
essentially a range `[a,b]`. When the analyzer looks at a program and returns
`[2,10]`, this amounts to “evidence” that when the program is run, it is
guaranteed to produce integer results between `2` and `10`.

The idea behind abstract interpretation is that we “interpret” the program
using symbolic, or approximate representations for values. Do do this, we need
to define implementation of operations (like plus and if) which take as input
these approximate results, and return as output another approximate result.
Each of these operators must consider all possible concrete inputs which the
approximate inputs *represent* and produce an output which is an upper bound on
the set of possible outputs. This connection between analysis results and
“possible concrete results” is made through a formal interpretation of
approximate values. We notate this interpretation of possible values as `⟦_⟧`.
These symbols are called “oxford brackets” and the notation is overloaded and
interpreted based on context. E.g., `⟦[a,b]⟧` is the interpretation of the
range `[a,b]` and is equal to the set of numbers between `a` and `b`: `{i : a ≤
i ≤ b}`.

In designing a program analyzer via abstract interpretation, the game goes like
this:
- define approximations for concrete values
- define approximations for operations
- convert the standard interpreter to work over approximations instead of
  concrete values
As we play this game, we place “hats” on things to denote
“approximate-version-of”, e.g., `î ∈ ℤ̂` means “an approximate integer `î` is in
the set of approximate integers `ℤ̂`. This is a notational trick to avoid having
to come up with new names for everything. `thing^` is just an abstract form of
`thing`, and conceptually represents a set of possible `thing`s.

## Approximate Booleans

Booleans are easy to approximate because there are a finite number of
them–there are exactly two.

### Abstract Domain

We represent a set of possible booleans as literally a set of possible
booleans:

    b̂ ∈ 𝔹̂ ≜ ℘(𝔹)

the interpretation of abstract booleans is not interesting–it is the identity
mapping:

    ⟦_⟧ ∈ 𝔹̂ → ℘(𝔹)
    ⟦b̂⟧ ≜ b̂

## Abstract Operations

What operations do we support on booleans? The primary one is the conditional:
`IF`. Let's consider three types of programs which now appear in our “abstract
semantics” (aka program analyzer):

    IF b̂₁ THEN b̂₂ ELSE b̂₃

1. when `b̂₁ = ∅`
2. when `b̂₁ = {true}`
3. when `b̂₁ = {true,false}`

In (1), we have analyzed the guard `b̂₁` and determined that there are no
possible values that it could compute (e.g., either due to a runtime error, or
an infinite loop). The result of analyzing the conditional is then also `∅`,
indicating that there are no possible results.

In (2), we have analyzed the guard `b̂₁` and determined that there is exactly
one possible value that it could be: `true`. The result of analyzing the
conditional is then `b̂₂`, because this is the branch that would be taken in the
standard interpreter.

In (3), we have analyzed the guard and determined that it could return *either
true or false*. In this case, the set of possible results is `b̂₂ ∪ b̂₃`—any of
the booleans that the true branch could return, or any of the booleans that the
false branch could return.

The implementation of the conditional (when both branches return possible
booleans) is then:

    cond^ ∈ 𝔹̂ × 𝔹̂ × 𝔹̂ → 𝔹̂
    cond^(b̂₁,b̂₂,b̂₃) ≜ 
      { b̂₂ | true ∈ b̂₁ }
      ∪
      { b̂₃ | false ∈ b̂₁ }

## Approximate Integers

Integers are slightly harder to approximate.  First, there are an infinite
number of integers, so it would be hopeless to try to compute the set of
possible integers a program could return. E.g., consider this while loop where
we don't know the value of `x` (although we assume it is non-negative):

    i ≔ 0;
    while (i ≤ x) { i++; }

This program could return any positive integer, and there is no way to
represent this as a literal, constructed set of integers.

Second, even if we picked large and small integers as the “maximum” and
“minimum” possible integer, it would still be highly inefficient to keep around
the set of all possible integers that a program could compute. E.g., in the
same while program as before, constructing a huge set of possible integers is
still undesirable (even if possible).

### Abstract Domain

A solution to this problem is to consider ranges of possible integers,
represented by a pair of the lower bound and upper bound. We will extend the
lower-bound with negative infinity, and extend the upper bound with positive
infinity:

    î ∈ ℤ̂ ≈ LB × UB ⩴ [lb,ub]
    lb ∈ LB ≜ -∞ | i
    ub ∈ UB ≜ i | +∞

the interpretation of abstract integers is the set of integers within the
range, with unbounded sets when one of the bounds is infinite:

    ⟦_⟧ ∈ ℤ̂ → ℘(ℤ)
    ⟦[-∞,+∞]⟧ = ℤ
    ⟦[-∞,i]⟧ = {j | j ≤ i}
    ⟦[i,+∞]⟧ = {j | j ≥ i}
    ⟦[i,k]⟧ = {j | i ≤ j ≤ k}

### Abstract Operators

Next we need to define two types of operators:
1. how to *compute* (e.g., plus) over abstract integers (intervals)
2. how to *merge* two abstract integer results

Merging abstract results must always be defined for abstract domains because it
is often the case that you need to represent “either A or B could happen” due
to the fact that we no longer know exactly what values will flow through the
program. E.g.:

    b̂ ≜ {true,false}
    IF b̂ THEN [1,2] ELSE [4,5]

In this program we are analyzing a program fragment where (1) we know that the
guard could evaluate to either true or false (2) we know the true branch could
evaluate to either `1` or `2`, and (3) we know that the false branch could
evaluate to either `4` or `5`. What are the possible results of this program
fragment? A precise characterization is the set `{1,2,4,5}`, but we are
choosing to represent these sets as ranges for practical reasons, so an
“optimal” abstract result for this program would be `[1,5]` because it's the
tightest interval that includes the actual set of possible results.

*ASIDE: precision and optimality are different, precise notions in program
analysis. A precise result is one that represents `{1,2,4,5}`, which we cannot
achieve with a single interval. An optimal result is one that represents some
set larger than `{1,2,4,5}`, and for which a better representation does not
exist. `[1,5]` is technically optimal, because there is no better interval, but
it is not precise. In this specific sense.*

The “merging” operation is pronounced “join” and notated `⊔`. Join for
intervals looks like this:

    _⊔_ ∈ ℤ̂ × ℤ̂ → ℤ̂
    [lb₁,ub₁] ⊔ [lb₂,ub₂] ≜ [min(lb₁,lb₂),max(ub₁,ub₂)]

One small technicality is the fact that `lb` and `ub` could be negative or
positive infinity, but we interpret `min` and `max` on this extended set of
integers in the obvious way (`-∞` is smaller than everything else, and `+∞` is
bigger than everything else).

Another small technicality is the fact that one of the ranges could be *empty*,
e.g., in `[2,1]`. If we assume ranges could be empty, we can do better than the
above definition. E.g., because `[2,1]` represents the empty set of integers,
when you “join” this interval with another one, you should just leave the other
interval untouched. That is, we want `[2,1] ⊔ [100,200]` to be `[100,200]`, not
`[2,200]`. An “optimal” definition is then:

    _⊔_ ∈ ℤ̂ × ℤ̂ → ℤ̂
    [lb₁,ub₁] ⊔ [lb₂,ub₂] ≜ [lb₂,ub₂]                    if  ⟦[lb₁,ub₁]⟧ = ∅
    [lb₁,ub₁] ⊔ [lb₂,ub₂] ≜ [lb₁,ub₁]                    if  ⟦[lb₂,ub₂]⟧ = ∅
    [lb₁,ub₁] ⊔ [lb₂,ub₂] ≜ [min(lb₁,lb₂),max(ub₁,ub₂)]  if  ⟦[lb₁,ub₁]⟧ ≠ ∅  and  ⟦[lb₂,ub₂]⟧ ≠ ∅

Next we want to define operations over intervals, like plus. First, let's work
through some examples. What do we expect the abstract results to look like for
these programs:

    [1,2] +̂ [3,4]
    [1,4] +̂ [2,3]
    [1,3] +̂ [2,4]
    [-1,1] +̂ [-2,2]
    [2,1] +̂ [100,200]

We expect the results to look like this:

    [1,2] +̂ [3,4] = [4,6]
    [1,4] +̂ [2,3] = [3,7]
    [1,3] +̂ [2,4] = [3,7]
    [-1,1] +̂ [-2,2] = [-3,3]
    [2,1] +̂ [100,200] = [2,1]

How did we come up with those? The formula is simply to add the lower bounds,
and add the upper bounds.  In the last case, the idea is that if one of the
ranges is empty, then there are no numbers that it represents, and likewise
there are no numbers that could be produced by the plus.

    [lb₁,ub₁] +̂ [lb₂,ub₂] ≜ ∅                  if  ⟦[lb₁,ub₁]⟧ = ∅  or   ⟦[lb₁,ub₁]⟧ = ∅
    [lb₁,ub₁] +̂ [lb₂,ub₂] ≜ [lb₁+lb₂,ub₁+ub₂]  if  ⟦[lb₁,ub₁]⟧ ≠ ∅  and  ⟦[lb₁,ub₁]⟧ ≠ ∅

## Approximate Values and Answers

Now that we have defined join and plus for abstract integers, we need to decide
how to represent abstract values and answers, and how to perform operations on
those representations.

### Abstract Domain

We start from the intuition that an abstract value should represent a set of
concrete values. Because concrete values are either integers or booleans, we
can pretend instead that values come from the set of “integers or booleans”
which is formed by a disjoint union: `ℤ ⊎ 𝔹`. Abstract values are
then *conceptually* defined as:

    value^ ≈ ℘(ℤ ⊎ 𝔹)

now we are going to rely on a correspondence between the algebra of numbers and
the algebra of sets, and a basic fact about numbers. First, the cardinality
(number of elements, written `|X|`) of set-level connectives is mirrored by
numeric operations:

    |A ⊎ B| = |A| + |B|
    |A × B| = |A||B|
    |A → B| = |B|^|A|
    |℘(A)| = 2^|A|

The formula from powersets is a happy coincidence with powersets `X ∈ A` being
isomorphic to characteristic functions `φ ∈ A → 𝔹`.

A basic property of numbers is that:

    2ᵃ⁺ᵇ = 2ᵃ2ᵇ

and in the land of sets, this establishes an isomorphism between `℘(A⊎B)` and
`℘(A)×℘(B)`. An example of this isomorphism is that these two English
statements are equivalent:

> Apples and cucumbers are among the set of fruits *or* vegetables I ate
> this morning.

> Apples are among the set of fruits I ate this morning *and* cucumbers are
> among the set of vegetables  I ate this morning.

We use this isomorphism to split `℘(ℤ ⊎ 𝔹)` into an equivalent set `℘(ℤ) ×
℘(𝔹)`. We now much choose how to represent sets of integers (we will do this
using `ℤ̂` defined above), and how to represent sets of booleans (we will do
this directly).

An abstract value is then:

    v̂ ∈ value^ ≜ ℤ̂ × ℘(𝔹) ⩴ ⟨î,b̂⟩

We extend this idea to abstract answers, starting from the definition of concrete answers:

    a ∈ answer ≜ {BAD} ⊎ ℤ ⊎ 𝔹

and for its abstraction we arrive at:

    â ∈ answer^ ≜ 𝔹 × ℤ̂ × 𝔹̂ ⩴ ⟨b,î,b̂⟩

where the boolean is a flag as to whether or not the program could fail (could
return `BAD`). There is one element in `{BAD}`, and there are two elements in
`℘({BAD})`, so we may as well just represent this two element set as a bool.

### Abstract Operations

We define join for abstract answers by joining each of the intermediate results
pairwise:

    _⊔_ ∈ answer^ × answer^ → answer^
    ⟨b₁,î₁,b̂₁⟩ ⊔ ⟨b₁,î₂,b̂₂⟩ = ⟨b₁∨b₂,î₁⊔î₂,b̂₁∪b̂₂⟩

Plus is a little more tricky. Consider the following program:

    â ≜ ⟨true,[1,2],∅⟩
    â + 5

the abstract result should be:

    ⟨true,[6,7],∅⟩

indicating that (1) the program could fail, and (2) it may return integers
within the range `[6,7]`, and (3) there are no booleans it could possibly
return.

What about:

    â ≜ ⟨false,[1,2],{true}⟩
    â + 5

the abstract result should be the same as before:

    ⟨true,[6,7],∅⟩

The reason this program could fail is because the left-hand side argument could
be a boolean `true`, which will cause the plus to fail with a runtime type
error. The program *cannot* return any booleans, because booleans are never a
possible output to plus when it succeeds.

Following these intuitions, we design plus for answers as follows:

    _+̂_ ∈ answer^ × answer^ → answer^
    ⟨b₁,î₁,b̂₁⟩ +̂ ⟨b₂,î₂,b̂₂⟩ ≜ ⟨b′,î′,b̂′⟩
      where b′ = b₁ ∨ b₂ ∨ (b̂₁ ≠ ∅) ∨ (b̂₂ ≠ ∅)
            î′ = î₁ +̂ î₂
            b̂′ = ∅

## The Analyzer

The analyzer for a core language is just a slightly non-standard interpreter
with abstract values:

    e ∈ expr ⩴ i | e + e
             | b | IF e THEN e ELSE e
             | x | LET x = e IN e
    γ̂ ∈ env^ ≜ var ⇀ answer^

    analyze ∈ env^ × expr → answer^
    analyze(γ̂,i) ≜ ⟨false,[i,i],∅⟩
    analyze(γ̂,e₁+e₂) ≜ analyze(γ̂,e₁) +̂ analyze(γ̂,e₂)
    analyze(γ̂,b) ≜ ⟨false,⊥,{b}⟩
    analyze(γ̂,IF e₁ THEN e₂ ELSE e₃) ≜ cond^(analyze(γ̂,e₁),analyze(γ̂,e₂),analyze(γ̂,e₁))
    analyze(γ̂,x) ≜ γ̂(x)        if  x ∈ γ
    analyze(γ̂,x) ≜ ⟨true,⊥,∅⟩  if  x ∉ γ
    analyze(γ̂,LET x = e₁ IN e₂) ≜ ⟨b₁∨b₂,î₂,b̂₂⟩
      where ⟨b₁,î₁,b̂₁⟩ = analyze(γ̂,e₁)
            ⟨b₂,î₂,b̂₂⟩ = analyze(γ̂[x↦⟨b₁,î₁,b̂₁⟩],e₂)

## Lattices and Partial Orders

Lattices are the general structure that each abstract domain should have, and
partial orders are the notion of ordering that lattices induce.

A lattice is some set `A` with the two special elements called “top” and
“bottom”:

    ⊥ ∈ A
    ⊤ ∈ A

and two special operators called “join” and “meet”, or “least-upper-bound” and
“greatest-lower-bound”.

    _⊔_ ∈ A × A → A
    _⊓_ ∈ A × A → A

along with these operators, there is an ordering (a relation) induced by the
operators:

    _⊑_ ∈ ℘(A × A)

You should use powersets (whose elements are “just sets”) as your grounding
intuition for lattices. Lattices enjoy most of the nice properties that sets
have, except for one specific one, distributivity:

    (A ∪ B) ∩ C = (A ∩ C) ∪ (B ∩ C)

This is true in set world, but not true in lattice world. Lattice symbols and
ordering are intended to suggest analogies with set-based operations:

    ⊥ ≈ ∅
    ⊤ ≈ A
    _⊔_ ≈ _∪_
    _⊓_ ≈ _∩_
    _⊑_ ≈ _⊆_

The ordering is related to join and meet (and is often *defined* in terms of)
in the following way:

    x ⊑ y ⬄  x ⊔ y = y
    x ⊑ y ⬄  x ⊓ y = x

This is also true of sets:

    x ⊆ y ⬄ x ∪ y = y
    x ⊆ y ⬄ x ∩ y = x

Two elements of a lattice need not be ordered in either direction. This is also
true of sets: for any sets `X` and `Y`, it need not be the case that `X ⊆ Y` or
`Y ⊆ X`. E.g., {1,2,3} and {2,3,4}.

General properties of lattices are the following equations (which are also true
of sets):

    ⊥ ⊔ x = x
    ⊤ ⊔ x = ⊤
    x ⊔ y = y ⊔ x
    (x ⊔ y) ⊔ z = x ⊔ (y ⊔ z)
    x ⊔ x = x

    ⊤ ⊓ x = x
    ⊥ ⊓ x = ⊥
    x ⊓ y = y ⊓ x
    (x ⊓ y) ⊓ z = x ⊓ (y ⊓ z)
    x ⊓ x = x

## Fixpoints and Widening

Fixpoint-finding and widening are necessary techniques to achieve tractable,
computable analyses for non-trivial programs (e.g., even to handle a simple
while loop).

Consider this example (in an imperative language):

    function f(x) {
      assert(x&gt;0);
      i ≔ 0;
      while(i&lt;x) { i⧺; }
      return i;
    }

This program takes a strictly positive number as input, and returns that same
number as output. It always terminates. The reason why this terminates is due
to a loop invariant where `i ≤ x`. When the loop exits, we know that `i ≤ x`
due to the loop invariant,  and `¬ i < x` due to the guard failing, which
implies `i = x`.

Currently we do not track *relationships* between variables in our abstract,
just ranges of values. Our abstract interpreter might look at this program and
start off as “we know `x` is strictly positive and that`i` is `0`”.

    x = [1,∞]
    i = [0,0]
    ──────────────────
    while(i&lt;x) { i⧺; }

It will update `i` to account for the fact that `i` could be `0` (before the
loop) or `1` (after one loop iteration), and then try the loop again:

    x = [1,∞]
    i = [0,1]
    ──────────────────
    while(i&lt;x) { i⧺; }

A naive implementation of this analysis will loop forever, *even though our
concrete program didn't loop forever*. It is therefore especially important
that we teach our analysis how to stop at some point–not just for looping
programs, but for non-looping ones too.

Let's try a different version of this program with booleans:

    function f(x) {
      i ≔ true;
      while(i) { i = i ∧ x; }
      return i;
    }

we accumulate facts about `x` (could be any boolean) and `i` (definitely true):

    x = {true,false}
    i = {true}
    ──────────────────
    while(i) { i = i ∧ x; }

we know the loop gets taken at least once, resulting in:

    x = {true,false}
    i = {true,false}
    ──────────────────
    while(i) { i = i ∧ x; }

now one of two things happens: (1) we take the loop again, and `x` and `i`
don't change, or (2) we exit the loop. The “`x` and `i` don't change” bit is
the crucial thing to notice. This means we have reached a “fixed-point” for the
input loop as a transformation on the (abstracted) state of the program. We
could run the loop once more or 10 billion times more, the result will stay the
same. It is therefore safe to stop here, not run the loop any longer, and
report the current results as an abstraction of *any possible number of runs*
of the loop.

This technique in general is called Kleene fixpoint iteration and relies on (1)
a proper lattice, (2) the lattice not having any infinitely ascending chains
(i.e., is either finite or can be ascended in a finite number of steps), (3)
the update to analysis being monotonic, and (4) iterating the loop, starting at
bottom, until it reaches a fixpoint. Kleene's fixpoint theorem tells you this
will always terminate in a *finite* number of steps, and is a sound
approximation of any *infinite* number of loop rounds.

In order to make this work for the interval lattice, we can't rely on the fact
that the lattice is finite (because it isn't), and instead we need to find a
way to climb the lattice in a finite number of steps. To do this, we notice
when one side of the interval is growing towards negative or positive infinity,
and just jump there pre-maturely as a conservative approximation.

As before, we go from here:

    x = [1,∞]
    i = [0,0]
    ──────────────────
    while(i&lt;x) { i⧺; }

to here

    x = [1,∞]
    i = [0,1]
    ──────────────────
    while(i&lt;x) { i⧺; }

and notice that the upper bound for `i` is marching towards infinity. We could
do this once more (for good measure):

    x = [1,∞]
    i = [0,2]
    ──────────────────
    while(i&lt;x) { i⧺; }

and see that yes, indeed, things are not looking good for that upper bound.
Let's bump it to infinity pre-emptively, and then run again:

    x = [1,∞]
    i = [0,+∞]
    ──────────────────
    while(i&lt;x) { i⧺; }

Here the input bounds on `x` and `i` are not changed by the loop–we have
reached a fixed-point. We can stop running the loop, and return `i = [0,+∞]` as
a conservative approximation for the function's behavior. The important thing
is that we arrived at the answer in a low constant number of loop iterations.
</pre>

</main>

<!-- Bootstrap core JavaScript -->
<!-- ================================================== -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<!-- ================================================== -->

<script>
</script>
  
<!-- Showdown -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/1.8.6/showdown.min.js"></script>

<!-- Darais JS -->
<script src="http://david.darais.com/js/darais-v0.0.0.2.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-70126522-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-70126522-1');
</script>

</body>
</html>
